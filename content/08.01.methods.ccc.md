## Methods

The code needed to reproduce all of our analyses and generate the figures is available in [https://github.com/greenelab/ccc](https://github.com/greenelab/ccc).
We provide scripts to download the required data and run all the steps.
A Docker image is provided to use the same runtime environment.


### The CCC algorithm {#sec:ccc_algo .page_break_before}

The Clustermatch Correlation Coefficient (CCC) is designed to compute a similarity score, denoted as $c$, which ranges from 0 to 1, between any two numerical or categorical features or variables, $\mathbf{x}$ and $\mathbf{y}$, across $n$ observations.
The fundamental premise of CCC is that if two features, $\mathbf{x}$ and $\mathbf{y}$, exhibit similarity, then clustering the $n$ observations based on each of these features independently should yield comparable partitions.
For instance, consider $\mathbf{x}=(11, 27, 32, 40)$ and $\mathbf{y}=10\mathbf{x}=(110, 270, 320, 400)$, where the number of observations, $n$, equals 4.
Dividing each variable into two clusters ($k=2$) based on their median values (29.5 for $\mathbf{x}$ and 295 for $\mathbf{y}$) results in the partitions $\Omega^{\mathbf{x}}_{k=2}=(1, 1, 2, 2)$ for $\mathbf{x}$ and $\Omega^{\mathbf{y}}_{k=2}=(1, 1, 2, 2)$ for $\mathbf{y}$.
The concordance between $\Omega^{\mathbf{x}}_{k=2}$ and $\Omega^{\mathbf{y}}_{k=2}$ can then be quantified using a partition similarity metric, such as the adjusted Rand index (ARI) [@doi:10.1007/BF01908075], which, in this scenario, would yield the maximum score of 1.0.
It is important to note that the same cluster count, $k$, may not effectively reveal the relationship between any two features.
For example, in the quadratic scenario depicted in Figure @fig:datasets_rel, CCC generates a score of 0.36 when objects are grouped into four clusters based on one feature and into two based on the other.
Opting for just two clusters in this case would result in a CCC score of 0.02.
Consequently, the CCC algorithm actively seeks the optimal cluster count within a predefined maximum, $k_{\mathrm{max}}$, which serves as its sole parameter.

$$
c \in \left[0,1\right]
$$

where $c$ represents the similarity score between $\mathbf{x}$ and $\mathbf{y}$, and

$$
\Omega^{\mathbf{x}}_{k}, \Omega^{\mathbf{y}}_{k}
$$

are the partitions of $\mathbf{x}$ and $\mathbf{y}$ into $k$ clusters, respectively.

![
](images/intro/ccc_algorithm/ccc_algorithm.svg "CCC algorithm"){width="75%"}

The primary operation of the algorithm designated as `ccc` involves the creation of two sets of partitions, denoted as $\Omega^{\mathbf{x}}$ and $\Omega^{\mathbf{y}}$, corresponding to each variable $\mathbf{x}$ and $\mathbf{y}$, respectively (as indicated in lines 14 and 15 of the algorithm).
Subsequently, the algorithm calculates the Adjusted Rand Index (ARI) for every possible pairing of partitions within $\Omega^{\mathbf{x}}$ and $\Omega^{\mathbf{y}}$ (referenced in line 16).
The objective is to identify and retain the pair of partitions that yields the highest ARI value.
Given the nature of ARI, which is unbounded below and can produce negative values that lack interpretative value in this context, the `ccc` algorithm is designed to return results confined within the range of 0 to 1 (as implemented in line 17).

The Adjusted Rand Index (ARI) is a measure used to assess the similarity between two data clusterings, with a higher ARI indicating a greater degree of similarity.
It is defined as:

$$
ARI = \frac{\text{Index} - \text{Expected Index}}{\text{Max Index} - \text{Expected Index


The CCC (Correlation Coefficient based on Clustering) algorithm is designed to compute similarity values efficiently by leveraging the inherent characteristics of the data.
This is achieved by partitioning the data into clusters, which can be formed based on either numerical or categorical features.
For numerical features, the algorithm employs a quantile-based clustering approach.
Specifically, the `get_partitions` function, in its lines 2 to 5, utilizes quantiles to create clusters.
An illustrative example of this is the use of the median to generate two clusters ($k=2$), with the process allowing for the creation of up to $k=k_{\mathrm{max}}$ clusters. 

$$ k = 2 \text{ to } k_{\mathrm{max}} $$

In this context, $k$ represents the number of clusters generated from the data.

For categorical features, as detailed in lines 7 to 9 of the `get_partitions` function, the algorithm simply groups objects based on their category.
This methodological approach facilitates the integration of numerical and categorical variables within the same framework.
Since clustering does not presuppose an inherent order among the clusters, both types of variables can be seamlessly incorporated into the analysis.
This flexibility is a key strength of the CCC algorithm, allowing it to accommodate a wide variety of data types and structures, thus making it particularly suitable for complex datasets such as those encountered in gene expression studies.


In our analysis, we consistently set $k_{\mathrm{max}}$ to 10.
This parameter choice implies that, for each pair of genes analyzed, a total of 18 partitions are createdâ€”9 for each gene, with $k$ ranging from 2 to 10.
Consequently, this leads to the performance of 81 Adjusted Rand Index (ARI) comparisons to assess the similarity between the clustering structures.
Opting for lower values of $k_{\mathrm{max}}$ could potentially decrease the computational burden; however, this reduction comes at the cost of potentially overlooking more intricate or general patterns in the data.
Our illustrative examples, as depicted in Figure @fig:datasets_rel, indicate that setting $k_{\mathrm{max}}$ to 2 would constrain the Correlation Coefficient Calculator (CCC) to identify solely linear relationships.
This setting might be appropriate in scenarios where the interest lies exclusively in linear correlations.
Moreover, a $k_{\mathrm{max}}$ value of 2 results in the generation of merely two partitions and necessitates a single ARI comparison.
To accommodate diverse research needs, our Python-based implementation of the CCC offers flexibility in specifying $k_{\mathrm{max}}$.
For instance, rather than limiting $k_{\mathrm{max}}$ to a single integer value, users have the option to input a custom list of integers.
For example, specifying `[2, 5, 10]` as the parameter would direct the algorithm to partition the data into clusters of two, five, and ten, respectively.
This feature enhances the utility of the CCC by allowing for tailored analyses that can adapt to the specific requirements of different datasets and research questions.


For a single pair of features (genes in our study), generating partitions or computing their similarity can be parallelized.
We used three CPU cores in our analyses to speed up the computation of CCC.
A future improved implementation of CCC could potentially use graphical processing units (GPU) to parallelize its computation further.


A Python implementation of CCC (optimized with `numba` [@doi:10.1145/2833157.2833162]) can be found in our Github repository [@url:https://github.com/greenelab/clustermatch-gene-expr], as well as a package published in the Python Package Index (PyPI) that can be easily installed.
