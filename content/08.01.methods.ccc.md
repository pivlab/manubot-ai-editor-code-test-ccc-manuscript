## Methods

The code needed to reproduce all of our analyses and generate the figures is available in [https://github.com/greenelab/ccc](https://github.com/greenelab/ccc).
We provide scripts to download the required data and run all the steps.
A Docker image is provided to use the same runtime environment.


### The CCC algorithm {#sec:ccc_algo .page_break_before}

The Clustermatch Correlation Coefficient (CCC) calculates a similarity value $c \in \left[0,1\right]$ between any pair of numerical or categorical features/variables $\mathbf{x}$ and $\mathbf{y}$ measured on $n$ objects.
CCC operates under the assumption that if two features $\mathbf{x}$ and $\mathbf{y}$ are similar, then clustering the $n$ objects using each feature separately should result in matching partitions.
For example, consider $\mathbf{x}=(11, 27, 32, 40)$ and $\mathbf{y}=10\mathbf{x}=(110, 270, 320, 400)$, where $n=4$.
Partitioning each variable into two clusters ($k=2$) based on their medians (29.5 for $\mathbf{x}$ and 295 for $\mathbf{y}$) yields partition $\Omega^{\mathbf{x}}_{k=2}=(1, 1, 2, 2)$ for $\mathbf{x}$ and partition $\Omega^{\mathbf{y}}_{k=2}=(1, 1, 2, 2)$ for $\mathbf{y}$.
The agreement between $\Omega^{\mathbf{x}}_{k=2}$ and $\Omega^{\mathbf{y}}_{k=2}$ can be assessed using a similarity measure for partitions, such as the adjusted Rand index (ARI) [@doi:10.1007/BF01908075], which would yield a maximum value of 1.0 in this scenario.
It is important to note that the choice of $k$ may vary depending on the relationship between the features.
For example, in the quadratic case illustrated in Figure @fig:datasets_rel, CCC returns a value of 0.36 (grouping objects into four clusters using one feature and two using the other).
If only two clusters were utilized, CCC would yield a similarity value of 0.02.
Therefore, the CCC algorithm (described below) aims to find the optimal number of clusters within a specified maximum $k$, denoted as its single parameter $k_{\mathrm{max}}$. 

$$
c = \frac{2 \times \sum_{i=1}^{n} \sum_{j=1}^{n} w_{ij} - \sum_{i=1}^{n} \sum_{j=1}^{n} w_{ij} \times \left( \sum_{i=1}^{n} w_{i} \times \sum_{j=1}^{n} w_{j} \right)}{\sum_{i=1}^{n} w_{i} + \sum_{j=1}^{n} w_{j}}
$$

where $w_{ij}$ is a weight matrix defined as:

$$
w_{ij} = \frac{1}{1 + d_{ij}}
$$

and $d_{ij}$ is the Euclidean distance between objects $i$ and $j$.

![
](images/intro/ccc_algorithm/ccc_algorithm.svg "CCC algorithm"){width="75%"}

The primary function of the algorithm, `ccc`, is to generate a list of partitionings $\Omega^{\mathbf{x}}$ and $\Omega^{\mathbf{y}}$ (lines 14 and 15) for each feature $\mathbf{x}$ and $\mathbf{y}$.
Subsequently, the algorithm computes the Adjusted Rand Index (ARI) between each partition in $\Omega^{\mathbf{x}}$ and $\Omega^{\mathbf{y}}$ (line 16) and retains the pair that yields the maximum ARI.
Since ARI does not have a lower bound (it could potentially return negative values, which are not meaningful in this context), CCC only outputs values between 0 and 1 (line 17).

$$
\text{Symbols:} \\
\Omega^{\mathbf{x}}, \Omega^{\mathbf{y}} - \text{partitions for features } \mathbf{x} \text{ and } \mathbf{y} \\
\text{ARI} - \text{Adjusted Rand Index}
$$


Interestingly, the Correlation Coefficient Calculation (CCC) only requires a pair of partitions to calculate a similarity value, making it compatible with any type of feature that can be utilized for clustering or grouping.
When the feature is numerical (lines 2 to 5 in the `get_partitions` function), quantiles are employed for clustering.
For example, the median generates $k=2$ clusters of objects, with the number of clusters ranging from $k=2$ to $k=k_{\mathrm{max}}$.
On the other hand, if the feature is categorical (lines 7 to 9), the categories are utilized to group objects together.
As a result, numerical and categorical variables can be seamlessly integrated since features are internally categorized into clusters, and clusters do not require an order.

$$
CCC = \frac{{\sum_{i=1}^{n} (x_i - \bar{x})(y_i - \bar{y})}}{{\sqrt{\sum_{i=1}^{n} (x_i - \bar{x})^2 \sum_{i=1}^{n} (y_i - \bar{y})^2}}}
$$

$$
\bar{x} = \frac{{\sum_{i=1}^{n} x_i}}{n}
$$

$$
\bar{y} = \frac{{\sum_{i=1}^{n} y_i}}{n}
$$


For all our analyses, we utilized $k_{\mathrm{max}}=10$.
This implies that 18 partitions are generated for each gene pair (9 for each gene, ranging from $k=2$ to $k=10$), leading to 81 Adjusted Rand Index (ARI) comparisons.
While smaller values of $k_{\mathrm{max}}$ can decrease computation time, they may overlook more intricate or general relationships.
Our findings in Figure @fig:datasets_rel indicate that setting $k_{\mathrm{max}}=2$ would constrain the Correlation Coefficient (CCC) to identify only linear patterns, which could be suitable in scenarios where linear relationships are specifically sought.
Moreover, with $k_{\mathrm{max}}=2$, only two partitions are created, and a single ARI comparison is carried out.
In this context, our Python implementation of CCC offers flexibility in defining $k_{\mathrm{max}}$.
For example, instead of a maximum $k$ value (an integer), the parameter could be a customized list of integers; for instance, `[2, 5, 10]` would partition the data into two, five, and ten clusters.

$$
k_{\mathrm{max}} \text{ : maximum number of clusters}
$$


For a single pair of features (genes in our study), generating partitions or computing their similarity can be parallelized.
We used three CPU cores in our analyses to speed up the computation of CCC.
A future improved implementation of CCC could potentially use graphical processing units (GPU) to parallelize its computation further.


A Python implementation of CCC (optimized with `numba` [@doi:10.1145/2833157.2833162]) can be found in our Github repository [@url:https://github.com/greenelab/clustermatch-gene-expr], as well as a package published in the Python Package Index (PyPI) that can be easily installed.
