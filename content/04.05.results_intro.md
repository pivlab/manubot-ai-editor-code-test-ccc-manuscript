### A robust and efficient not-only-linear dependence coefficient

![
**Different types of relationships in data.**
Each panel contains a set of simulated data points described by two generic variables: $x$ and $y$.
The first row shows Anscombe's quartet with four different datasets (from Anscombe I to IV) and 11 data points each.
The second row contains a set of general patterns with 100 data points each.
Each panel shows the correlation value using Pearson ($p$), Spearman ($s$) and CCC ($c$).
Vertical and horizontal red lines show how CCC clustered data points using $x$ and $y$.
](images/intro/relationships.svg "Different types of relationships in data"){#fig:datasets_rel width="100%"}

The CCC calculates the similarity between pairs of variables, whether they have numerical or categorical values.
It assumes that if two variables describe n data points, the clusters of those points should align.
For numerical values, CCC uses quantiles to create clusters (e.g., the median splits data into two clusters).
The CCC is defined as the maximum adjusted Rand index between the clusterings, with a range of 0 to 1.
More information on the CCC algorithm is available in the Methods section.


We analyzed the behavior of the Pearson ($p$), Spearman ($s$), and CCC ($c$) correlation coefficients using various simulated data patterns.
Figure @fig:datasets_rel shows the results for Anscombe's quartet, consisting of four synthetic datasets with different patterns but the same data statistics.
This classic dataset highlights the limitations of relying solely on summary statistics, as it can mask both undesirable patterns, like outliers, and desirable ones, such as biologically meaningful nonlinear relationships.
The importance of looking beyond simple statistics is further emphasized by the "Datasaurus" dataset, which has been revisited in recent studies.


Anscombe I and III display clear linear patterns, with one outlier in Anscombe III.
The Correlation Coefficient based on Machine Learning (CCC) accurately separates data points in these examples, yielding a strong relationship value of 1.0.
Anscombe II exhibits a partially quadratic relationship, which is interpreted as linear by traditional correlation methods.
However, CCC identifies a more complex relationship with a value of 0.34.
In Anscombe IV, a vertical line of data points with one outlier is observed.
CCC correctly indicates no association with a value of 0.00 due to the outlier and the variation in values for one variable.
This demonstrates that CCC is sensitive to deviations from linear patterns.
Pearson's correlation coefficient remains consistent across all examples, while Spearman's coefficient varies.
Overall, Pearson and Spearman are effective in detecting linear patterns but are less robust when faced with nonlinear relationships or outliers.


We examined various types of relationships, as shown in Figure @fig:datasets_rel (second row), including those observed in gene expression data.
For a random/independent pair of variables, all coefficients approached zero.
The non-coexistence pattern, identified by all coefficients, indicates a scenario where one gene ($x$) may be active while the other ($y$) is suppressed, suggesting a potentially significant biological association (e.g., microRNA regulation).
In the case of the quadratic and two-lines examples, Pearson and Spearman coefficients failed to capture the nonlinear relationship between variables $x$ and $y.
The CCC method demonstrated its ability to capture different levels of complexity in these relationships.
For the quadratic pattern, CCC segmented $x$ into four clusters to optimize the Adjusted Rand Index (ARI).
In the two-lines example, where two linear relationships with distinct slopes were present, neither Pearson nor Spearman coefficients detected the pattern ($p=-0.12$ and $s=0.05$, respectively).
CCC addressed this by utilizing eight clusters for $x$ and six for $y$, resulting in a coefficient of $c=0.31$.
